{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb44e6de",
   "metadata": {},
   "source": [
    "# Simple MAST-1D Tutorial Run: Single Reach, Constant Parameters\n",
    "\n",
    "This run sets up the basic input parameters for a MAST-1D run as an object, then passes these to the model. The run here is simple, with no lateral sediment supply and with a single, constant slope, constant parameter reach.\n",
    "\n",
    "To use this notebook, it should be saved in the MAST_1D folder of the MAST-1D project, as cloned from GitHub: https://github.com/jwlauer/MAST-1D-2.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f97a4",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d7d27",
   "metadata": {},
   "source": [
    "Import the required standard libraries that will be used for setting up the inputs. There are a number of other libraries importated by the MAST-1D classes. An Anaconda distribution of Python should include the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e0ab985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "sys.path.append(\"..\")\n",
    "from Hydrology.clsTimeSeries import clsTimeSeries\n",
    "from MAST_1D.clsModel import clsModel\n",
    "from MAST_1D.clsInputs import clsInputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c91c8e",
   "metadata": {},
   "source": [
    "Create an empty instance of the inputs object that will be used to store a wide range of input data and then pass it to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82133fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = clsInputs() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9cee29",
   "metadata": {},
   "source": [
    "## I.A  Import csv with node-specific inputs for some attributes (optional)\n",
    "\n",
    "Here you can import a .csv file with spacially-explicit initial conditions. It is commented out in this example and has not been tested with recent revisions to the model.  However, in theory, it is straightforward to create a spreadsheet and/or input textfile that is used to specify basic basic properties for each node (width, reach length represented, coordinate, elevation, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59e8c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputfile = os.path.join(os.pardir, 'Elwha_spatial_data', 'UR_Valley_Nodes_sinuosity.csv')\n",
    "#\n",
    "## open the file in universal line ending mode \n",
    "#with open(inputfile, 'rU') as infile: # This loop copied from Stack Overflow.\n",
    "#  # read the file as a dictionary for each row ({header : value})\n",
    "#  reader = csv.DictReader(infile)\n",
    "#  data = {}\n",
    "#  for row in reader:\n",
    "#    for header, value in row.items():\n",
    "#      try:\n",
    "#        data[header].append(value)\n",
    "#      except KeyError:\n",
    "#        data[header] = [value]\n",
    "#        \n",
    "#inputs.BcNodes = map(lambda x: float(x), data['InitialBc'])\n",
    "#inputs.BfNodes = map(lambda x: float(x), data['Avg_width'])\n",
    "#inputs.dxf = map(lambda x: float(x), data['Valley_length']) # Optional length of valley to determine node length with sinuosity\n",
    "#inputs.Canyon = map(lambda x: bool(int(x)), data['Canyon'])\n",
    "#inputs.ReachwideBedrock = False # If true, every reach will only be allowed to degrade a user-specified amount and bed will become 'partly-alluvial'\n",
    "#inputs.PartlyAlluvialMin = -.2\n",
    "#inputs.ChSinNodes = map(lambda x: float(x), data['Avg_Sinuosity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3a33d",
   "metadata": {},
   "source": [
    "## I.B  Import reach conditions from a previous run (optional)\n",
    "\n",
    "Similar to the code commented above, it is possible to save a run and then simply re-load it as the intial condition for a future run. Again, this is commented out here and is relatively untested.  However, the code later looks for the inputs.initialcond flag, so this must be set either to \"True\" or \"False\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a67e81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.initialcond = False # If you are using a prior run as initial conditions, True; if starting from scratch, False\n",
    "#inputs.priorReach = 'D:\\MAST-1D_version_K6\\Output\\Pre_vs_post_dam\\WholePeriod'+ '//' +'save.Reach' # File with initial conditions Reach object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0623f4d",
   "metadata": {},
   "source": [
    "## II. Set Reach-Average Channel Geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8a524",
   "metadata": {},
   "source": [
    "Set reach-average channel geometry. Note that you must specify these variables even if you previously loaded an initial conditions file from a previous run or defined nodes on a case-by-case basis. MAST-1D will set the feed and floodplain number based on the reach-average values specified here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1cf79a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.Nnodes = 66 #  Number of nodes\n",
    "inputs.Bc = 94. # Channel width (m)\n",
    "inputs.reachlength = 13673. # Length of reach (channel length) (m)\n",
    "inputs.Bf = 500 # Total valley width (m)\n",
    "inputs.ChSin = 1.02 # Channel sinuosity\n",
    "inputs.Slope = 0.0074 # Bed gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5146b507",
   "metadata": {},
   "source": [
    "## III. Choose Hydrograph or Flow Duration Curve Run\n",
    "\n",
    "The model allows for hydrographs or flow duration curves. For long-term runs, hydrograph data may not be available to represent the entire period of simualtion. In these cases, set the cyclinghydrograph flag to true, and the hydrograph will repeat.  In this section, the parameters for flow duration curves are also specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cc0e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.Hydrograph = True # True if supplying hydrograph instead of flow duration curve--not used for this demo\n",
    "inputs.CyclingHydrograph = False #Flag to determine if hydrograph is repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79cc948",
   "metadata": {},
   "source": [
    "## IV.A Timestep parameters for flow duration curve\n",
    "\n",
    "The total run length is also specified here using the MaxSteps variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fa1280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.MaxSteps = 2000 #  Total number of timesteps to run.\n",
    "inputs.dt = [0] # Timestep (years)--can add multiple values for timestep adjustment during run\n",
    "inputs.dtcount = [] # List of timesteps to instigate timestep interval change (length of list should be one fewer than dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e03e9",
   "metadata": {},
   "source": [
    "## IV.B  Timestep parameters for hydrograph\n",
    "MAST-1D is set up to run hydrographs with a daily resolution.  It will keep track\n",
    "of the date and instigate user-specified boundary condition changes based on the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.Tmult = 1 # Number of timesteps per day\n",
    "inputs.TmultHighFlow = 8 #150 # Number of timesteps for days with flow above High Flow Timestep Threshold\n",
    "inputs.TmultCyclingHydrograph = 27 #Number of timesteps per day for Cycling Hydrograph runs.\n",
    "inputs.StartDate = (2011,9,15) # (year, month, day).\n",
    "inputs.LowFlowThreshold = 40 # threshold discharge below which hydrograph runs ignore sediment transport\n",
    "inputs.HighFlowTimestepThreshold = 120 #300 # threshold discharge above which hydrograph runs use a shorter timestep."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b53c8c",
   "metadata": {},
   "source": [
    "## V. Specify Boundary Conditions\n",
    "\n",
    "The first of these is specific to a dam removal run. If the removal flag is set to true, the model looks for this flag and can use it to change boundary conditions at times that are hard-coded in the model. This should normally be false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf64b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.Removal = False # This is a custom variable that is used to set some boundary\n",
    "    # condition behavior for the Elwha River Dam removal (see Section VI.D in \n",
    "    # clsModel)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed86c9d",
   "metadata": {},
   "source": [
    "### Sediment\n",
    "The upstream feed is determined as a fraction of the computed sediment transport capacity of the upstream node. LoadFactor is a list that specifies what fraction of that capacity is provided as sediment feed at a given point in the run. The same factor applies to all sediment size classes.  \n",
    "\n",
    "The sediment supply can change at a user specified timestep, LoadFactorCount. This should be provided as a list if timesteps where a change in feed occurs (if using a duration-based run) or a tuple ((yy,m,dd)) for hydrograph runs.  Number of entries should be one less than LoadFactor.\n",
    "\n",
    "Feed type should be 'DurationCurve' if using a duration curve or 'RatingCurve' if using a hydrograph.  You can also create a custom method for applying feed--see Section VI.E in clsModel. Note that for many runs, supply is specified at the capacity of the upstream node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aab5130",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.LoadFactor = [0.8,0.8]  \n",
    "inputs.LoadFactorCount = [900] \n",
    "inputs.FeedType = \"RatingCurveUpperElwha\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5473e7c",
   "metadata": {},
   "source": [
    "### Hydraulics\n",
    "The downstream boundary for the gradually varied flow computation can be either a specified water surface or normal depth.  SetBoundary should be False for normal depth.  If a specified water surface elevation is used, it is set in BoundaryFactor.  The water surface elevation can change at timesteps specified in BoundaryFactorCount, which is a list of times to instigate WSE change.  The number of entries shold be one less than BoundaryFactor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb57eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.SetBoundary = False \n",
    "inputs.BoundaryFactor = [30.]\n",
    "inputs.BoundaryFactorCount = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19607c22",
   "metadata": {},
   "source": [
    "## VI: Hydraulic Control Parameters\n",
    "\n",
    "The backwater computation can be performed using either a Chezy equation or a Manning Equation to represent friction losses.  Set vfunc to True for Manning.  Friction factors for channel and floodplain, as well as form roughness and sinuosity factors and floodplain mannings roughness are also specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09f25d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.ManningStabilizer = 3 # Controls how much the water surface elevation changes\n",
    "    #with each iteration in the backwater calculation\n",
    "inputs.vfunc = True # Velocity function, True for Manning, False for Chezy\n",
    "inputs.Cfc = 0.0075 # 1/Cz^2 for channel\n",
    "inputs.Cff = 0.69 # 1/Cz^2 for floodplain\n",
    "inputs.ncAddons = 0.0066 # Form roughness component for Manning's n; \n",
    "    # will be added to calculated n value\n",
    "inputs.ncMultiplier = 1.15 # Sinuosity multiplier for Manning's n\n",
    "inputs.nf = 0.1 # Manning's n for floodplain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309cdb5",
   "metadata": {},
   "source": [
    "## VII.A Discharge Record for Flow Duration Curve\n",
    "Discharges are read into a list describing the characteristic discharge for each bin of the flow duration distribution.  Probabilities p are specified for each bin. These represent the fraction of time a given discharge occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4268a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.Qw = [\\\n",
    "30.,\\\n",
    "50.,\\\n",
    "70.,\\\n",
    "90.,\\\n",
    "150.,\\\n",
    "275.,\\\n",
    "455.,\\\n",
    "540.] \n",
    "\n",
    "inputs.p = [\\\n",
    "0.3,\\\n",
    "0.5,\\\n",
    "0.1,\\\n",
    "0.05,\\\n",
    "0.045,\\\n",
    "0.004,\\\n",
    "0.0007,\\\n",
    "0.0003]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8962ff84",
   "metadata": {},
   "source": [
    "## VII.B Discharge Record for Hydrograph\n",
    "Discharge timeseries can be specified on a node-by-node basis. Each node is given a code that corresponds with the discharge files specified here.  An along-channel coordinate representing the downstream end of the region of application of a given discharge file can also be specified.\n",
    "\n",
    "Discharge files should be stored in the \"Discharge_Files\" folder in the parent directory. See examples there for formatting.  \n",
    "\n",
    "MAST-1D also calculates initial floodplain and feed parameters based on a flow duration curve representing the modeled period, even when the hydrograph run is turned on.  A flow duration curve will be calculated automatically using DischargeFile and the NumberOfHydroBins variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48ed0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.DischargeFileID = [0]\n",
    "inputs.DischargeFileCoords = [0] \n",
    "inputs.DischargeFiles = ['Qfile15Sep2011pres']\n",
    "inputs.NumberofHydroBins = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c5cf8",
   "metadata": {},
   "source": [
    "## VIII. Grain Size and Sediment Related Parameters\n",
    "\n",
    "Set the bin boundaries (mm) for grain size distributions. The finest size class should be the silt/clay. There must be a lower bound (here it is estimated to be 0.002)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4ab33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.Dbdy = [\\\n",
    "0.002,\\\n",
    ".063,\\\n",
    "1.0,\\\n",
    "2.0,\\\n",
    "4.0,\\\n",
    "8.0,\\\n",
    "16.0,\\\n",
    "32.0,\\\n",
    "64.0,\\\n",
    "128.0,\\\n",
    "256.0,\\\n",
    "512.0,\\\n",
    "1024.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e034bf2",
   "metadata": {},
   "source": [
    "Set up the initial grain size distribution for the active layer of the channel. The length of the list should be one less than the number of grain size bin boundaries. In MAST-1D, the symbol \"F\" always represents a grain size fraction, so Fa indicates size fractions in the active layer. If these do not add up to 1, MAST-1D will normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "817afa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.Fa = [\n",
    "0.,\\\n",
    "7.0,\\\n",
    "4.3,\\\n",
    "4.7,\\\n",
    "4.7,\\\n",
    "5.7,\\\n",
    "7.4,\\\n",
    "15.,\\\n",
    "21.,\\\n",
    "20.,\\\n",
    "9.7,\\\n",
    "1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a60f6",
   "metadata": {},
   "source": [
    "Set up a possible sediment lag depsit in the substrate. To add lag deposits to the substrate, choose a fraction for the grainsize of choice.  If the lists are left blank, the substrate is composed of the same material as the Active Layer and Floodplain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2374744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.DLag = [] # List of indexes of grainsizes to alter\n",
    "inputs.FLag = [] # Fraction of GSD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb5543",
   "metadata": {},
   "source": [
    "Set other sediment-related parameters. In the past, there was a variable for computing sand load in suspension as a fraction of the sand load computed using the bed material transport formula. This was intended to result in realistic sand deposition rates on the floodplain, but this function is currently not enabled.  The MudFraction variable is similar in that the supply of material FINER than sand is specified as a fraction of the transport rate of the finest bed material size fraction.\n",
    "\n",
    "The floodplain number for bed material represents the fraction of bed material flux in water flowing across the floodplain that would get stored in the floodplain.\n",
    "\n",
    "It is possible to specify nodes where lateral sediment supply is provided.  This is done using a list of the nodes where lateral supply is provided, and then a list of multipliers (one for each node). The multiplier represents the fraction of the load computed for the upstream node that is supplied at the respective lateral source node.  To try this out, use the commented lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e1bbd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for suspended load\n",
    "inputs.FSandSusp = 0.12 # Fraction of sand in the suspension.  This parameter is \n",
    "    # not currently connected in the model.\n",
    "inputs.MudFraction = 18. # Mud feed multiplier (multiple of next finest size class)\n",
    "inputs.FlBed = .75 # Floodplain number for bed material\n",
    "\n",
    "# Bedload sediment transport equation\n",
    "inputs.TransFunc = 'WilcockCrowe' # Transport function; choices are 'WrightParker' and 'WilcockCrowe'\n",
    "inputs.TrinityFit = True # True is Trinity River form (Gaeuman 2009), False is normal Wilcock and Crowe        \n",
    "inputs.CalibrationFactor = 1.  # Calibration coefficient for critical shear stress\n",
    "\n",
    "# Lateral Sediment Supply\n",
    "#inputs.LateralSedimentSourceNodes = [20,60]  # indices of nodes with lateral supply\n",
    "#inputs.LateralMultiplier = [0.1,0.1]  # fraction of upstream supply for lateral source nodes\n",
    "\n",
    "inputs.LateralSedimentSourceNodes = []  # indices of nodes with lateral supply\n",
    "inputs.LateralMultiplier = []  # fraction of upstream supply for lateral source nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2ca7b",
   "metadata": {},
   "source": [
    "## VIII. Channel migration and width change\n",
    "\n",
    "In this section, there are flags that control how channel migration is handled in the model. If the widthchange flag is turned on, the constant migration rate is not used, and migration is computed as a function of bank erosion rate and vegetation encroachment rates.  If it is off, the lateral migration is a specified constant.  However, the constant migration rate has to be specified regardless of run type so that a plausible floodplain number can be computed that results in reasonable steady-state bank heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "780850d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.WidthChange = True # If true, turns off constant migration rate and \n",
    "    # channel-floodplain coupling is determined by width change functions\n",
    "inputs.migration = 1.2 # Channel migration rate (m/yr).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d5f6b7",
   "metadata": {},
   "source": [
    "### Vegetation Encroachment Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11cf64fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.BcMin = 40.  # Minimum channel width\n",
    "inputs.W = .07 # Narrowing constant--used to calibrate narrowing function.  \n",
    "    # As a starting guide, estimate the percentage of bar that is vegetated\n",
    "    # annually and double it.\n",
    "inputs.alphatau = 32. # Shear stress threshold for channel narrowing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89ca0c",
   "metadata": {},
   "source": [
    "### Bank Erosion Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b02828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.ErodeT = .55 # Fraction of near-bank sediment sourced from the active layer\n",
    "inputs.MobilityThreshold = 10**-7 # Mobility threshold for initiation of bank erosion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b6904",
   "metadata": {},
   "source": [
    "### Avulsion Terms\n",
    "Setting the avulsion threshold negative turns off avulsions. Use these with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d615c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.AvulsionExchange = .1\n",
    "inputs.AvulsionThreshold = -1.25 # Minimum bank height below which avulsion will occur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedbf463",
   "metadata": {},
   "source": [
    "## X. Reservoir Thickness and Exchange Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9995e199",
   "metadata": {},
   "source": [
    "### Sediment Reservoir Characteristics\n",
    "These define the geometry of the sediment reservoir layers and the number of substrate layers.  Porosity of the deposit is also specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb8724de",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.FloodplainL = 1.75 # Initial thickness of the active floodplain (m)\n",
    "inputs.ActiveLayerL = .4 # Initial thickness of the Active Layer\n",
    "inputs.LayerL = 1.5 # Thickness of substrate layers (m)\n",
    "inputs.NLayers = 2 # Number of substrate layers\n",
    "inputs.Hpb = 1.7 # Thickness of the point bar (constant through time)\n",
    "inputs.lambdap = 0.5 # Porosity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5724cd1",
   "metadata": {},
   "source": [
    "### Reservoir exchange parameters\n",
    "These parameters influece the rate at which sediment is exchanged from reservoir to reservoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "108e2fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.Kbar = 1/1000000. # Parameter controlling fraction washload in point bar deposits\n",
    "inputs.AlphaBed = .9 # Proportion of new substrate composed of active layer material\n",
    "    # (verses load material)\n",
    "inputs.AlphaBar = 1. # Parameter controlling similarity between bed material load \n",
    "    # and bar deposition\n",
    "inputs.AlphaPartlyAlluvial = 0.9 # Parameter controlling similarity between bed\n",
    "    # material load and deposition in the active layer of a partly alluvial node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c77ff",
   "metadata": {},
   "source": [
    "## XI. TRACER PROPERTIES \n",
    "\n",
    "The tracer component has not been tested in this version of MAST-1D, but should \n",
    "theoretically work.  They may need to be initialized in order to compute a run.  The decaying tracer is set up as Cosmogenic 14C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4fa99f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.NTracers = 1 # Number of tracers\n",
    "inputs.coj = [82.96, 1.98, 15.06] # production from different processes (at surface, presumably--not integrated over depth)\n",
    "inputs.Lcj = [160., 738., 2688.] # Attenuation rates (g/cm^2)\n",
    "inputs.Name = \"'14C'\"  # Name of radioisotopic tracer\n",
    "inputs.DecayConst = 0.000121 # Decay constant (can be zero for a cnservative tracer)\n",
    "inputs.ProductionRate = 15.1 # Nuclide production rate\n",
    "inputs.FalloutRate = 0. # Nuclide fallout rate--most relevant for fine sediment.\n",
    "\n",
    "inputs.TracerICFloodplain = 1.\n",
    "inputs.TracerICActiveLayer = 0.\n",
    "inputs.TracerICSubstrate = 0.\n",
    "inputs.TracerBCFeed = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44623502",
   "metadata": {},
   "source": [
    "## XII. OUTPUT SPECIFICATIONS \n",
    "\n",
    "There are three types of output:\n",
    "A. Text files of node attributes for each node over time periods of equal intervals\n",
    "    (for hydrographs and duration curves)\n",
    "B. Text files of node attributes for each node on user-specified dates (currently \n",
    "    for hydrographs only)\n",
    "C. JSON files with daily output at a given location. User specifies which \n",
    "    nodes and variables to write out. For hydrograph runs only.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348e53a4",
   "metadata": {},
   "source": [
    "### Specify Output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d19afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunName = \"ElwhaHydrographDemo_Simple_short\" # Name of the run (a folder of outputs files will be created\n",
    "    # under this name).\n",
    "inputs.Outputfolder = os.path.join(\"Output\",\"Demo\",RunName) # Parent folder for \n",
    "    # the output folder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e528e",
   "metadata": {},
   "source": [
    "### A.  General output\n",
    "\n",
    "Any node property can be saved at regular intervals. These are saved for each node in the reach. The properties to export are specified as a list of strings defining the property. The string follows the same syntax one would use to access the note property. For instance, the to output node.Slope for all nodes at regular intervals, the string 'Slope' should be included in the .Outputvars list. For node properties that are lists, the index of the list must be specified.\n",
    "\n",
    "For runs that are driven by a daily hydrograph, output can be provided very day. To limit the size of output files, this type of output is not saved for every node in the reach. As with varialbes that are output at regular intervals, the properties to save are listed as strings, but here they are strings of reach properties.  For instance, to save D50 of the grain size distribution of the active layer at the node with index 10, the string 'Node[10].ActiveLayer.GSD.D50' would be specified in DailyOutputvars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76cc6007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of dataslices to save.  Will be written at equal time intervals.\n",
    "inputs.NumberOfPrintouts = 50 \n",
    " \n",
    "# List variables to save at regular intervals (strings of clsNode attributes)\n",
    "inputs.Outputvars = ['Slope',\n",
    "                     'Bf',\n",
    "                     'Bc',\n",
    "                     'DC.Qwf[-1]',\n",
    "                     'DC.Sf[0]',\n",
    "                     'DC.Hc[0]',\n",
    "                     'DC.Hc[-1]',\n",
    "                     'DC.Uc[-1]',\n",
    "                     'DC.Uc[0]',\n",
    "                     'DC.WSE[0]',\n",
    "                     'DC.WSE[-1]',\n",
    "                     'DC.Qw[0]',\n",
    "                     'DC.Uc[0]',\n",
    "                     'ActiveLayer.GSD.D50',\n",
    "                     'ActiveLayer.GSD.D84',\n",
    "                     'Load.QsavBedTot',\n",
    "                     'Load.QsavBedTotFeed',\n",
    "                     'Floodplain.GSD.D50',\n",
    "                     'etabav',\n",
    "                     'Substrate[-1].C.GSD.D50',\n",
    "                     'CumulativeBedChange',\n",
    "                     'Floodplain.L',\n",
    "                     'Floodplain.GSD.F[0]',\n",
    "                     'Floodplain.GSD.D84',\n",
    "                     'CumulativeTotBedMaterialFeed',\n",
    "                     'SLatSourceAv[-1]',\n",
    "                     'CobbleMobility',\n",
    "                     'WidenRate',\n",
    "                     'NarrowRate',\n",
    "                     'PointBarSubsurfaceGSD.D50',\n",
    "                     ]\n",
    "\n",
    "# List variables for daily output (strings of clsReach attributes)    \n",
    "inputs.DailyOutputVars=['Node[0].DC.Qw[0]',\n",
    "                        'Node[-1].DC.Qw[0]',\n",
    "                        'Node[10].Load.QsjTot[0]',\n",
    "                        'Node[0].CumulativeTotFeed',\n",
    "                        'Node[-1].CumulativeTotFeed',\n",
    "                        'Node[10].Load.QsAvkLoad[0]',\n",
    "                        'Node[10].Load.QsAvkLoad[7]',\n",
    "                        'Node[10].ActiveLayer.GSD.D50',\n",
    "                        'Node[10].ActiveLayer.ExSed.InWidthChange[1]',\n",
    "                        'Node[10].ActiveLayer.ExSed.InWidthChange[7]',\n",
    "                        'Node[10].Bc',\n",
    "                        'Node[10].NarrowRate',\n",
    "                        'Node[10].WidenRate',\n",
    "                        'Node[10].CumulativeNarrowing',\n",
    "                        'Node[10].CumulativeWidening', \n",
    "                        'Node[10].ActiveLayer.GSD.F[0]',\n",
    "                        'Node[10].ActiveLayer.GSD.F[1]',\n",
    "                        'Node[10].ActiveLayer.GSD.F[7]',\n",
    "                        'Node[10].ActiveLayer.GSD.F[-1]',\n",
    "                        'Node[9].ActiveLayer.T[1,0]',\n",
    "                        'Node[10].ActiveLayer.T[1,0]',\n",
    "                        'Node[-1].ActiveLayer.T[1,0]',\n",
    "                        'Node[-1].ActiveLayer.T[7,0]',\n",
    "                        'Node[10].ActiveLayer.T[7,0]',\n",
    "                        'Node[0].Floodplain.T[1,0]',\n",
    "                        'Node[0].Load.TBedFeedk[0,0]',\n",
    "                        'Node[1].Load.TBedFeedk[0,0]',\n",
    "                        'Node[1].ActiveLayer.T[0,0]',\n",
    "                        'Node[0].ActiveLayer.T[0,0]',\n",
    "                        'Node[0].ActiveLayer.T[1,0]',\n",
    "                        'Node[10].FkPointBarDepositAnnualAverage[1]',\n",
    "                        'Node[10].Dfav[0]',\n",
    "                        'Node[10].Dfav[1]'\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99fbd8",
   "metadata": {},
   "source": [
    "### Output on specific dates (for hydrograph runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96154a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates (yyyy, m, dd) in which to output variables for model validation \n",
    "inputs.ValidateDates = [(2011, 9, 30),(2012, 9, 30),(2013, 9, 30),(2014, 9, 30),(2015, 9, 30),(2016, 9, 30)]  \n",
    "\n",
    "# Variables (attributes of clsNode) in which to output on specific dates for model validation\n",
    "inputs.Validatevars = ['CumulativeTotFeed','Bc','CumulativeNarrowing','CumulativeWidening','CumulativeTotalAvulsionWidth']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e4c35",
   "metadata": {},
   "source": [
    "### Output daily (for hydrograph runs)\n",
    "This feature has been superceded by the daily output variable method described earlier.  \n",
    "\n",
    "Here, the nodes for which output will occur on a daily basis are specified.  The variables to save are hard-coded in clsOutputSpecs (which is why the method is deprecated). Note that the file sizes of daily output can be up to several megabytes, so use judiciosly.  It is better to use inputs.DailyOutputVars to specify daily output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9209953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.DailyNodes = [0,35] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2f972",
   "metadata": {},
   "source": [
    "## Load the Hydrographs\n",
    "The user does not modify this section.\n",
    "\n",
    "### Define a function to load the hydrographs in case where there are several "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a04ac6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hydrographs(inputs):\n",
    "    #Initialize lists\n",
    "    inputs.Qlist = []\n",
    "    inputs.Qw = []\n",
    "    inputs.p = []\n",
    "    \n",
    "    for f in inputs.DischargeFiles:\n",
    "        # Load discharge files as a lists\n",
    "        DischargeFile = os.path.join(os.pardir,\"Discharge_Files\", f)\n",
    "        print(DischargeFile)\n",
    "        Qlist = open(DischargeFile).readlines()\n",
    "        Qlist = list(map(lambda x: float(x), Qlist))\n",
    "        binsize = (max(Qlist)-min(Qlist))/inputs.NumberofHydroBins\n",
    "        print('binsize = %s' %(binsize))\n",
    "        # Create a duration curve from the list for setting up equilibrium floodplain\n",
    "        # conditions and feed.  Other parameters can be customized (see ExtractDC function).\n",
    "        Q = clsTimeSeries([],Qlist) \n",
    "        Qw, p = Q.CreateDurationCurve(binsize)\n",
    "        print('number of bins made = %s' % len(Qw))\n",
    "        inputs.Qlist.append(Qlist)\n",
    "        inputs.Qw.append(Qw)\n",
    "        inputs.p.append(p)\n",
    "      \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da3e8d",
   "metadata": {},
   "source": [
    "## RUN THE MODEL (Reading in any necessary hydrographs)\n",
    "User does not modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe605d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Discharge_Files\\Qfile15Sep2011pres\n",
      "binsize = 25.468171824133332\n",
      "number of bins made = 15\n",
      "Model setup complete!  Starting timesteps...\n",
      "Saving regular output at count = 0\n",
      "Saving validation output at specified date of: 2011-09-30 \n",
      "2011-10-01\n",
      "Saving regular output at count = 37\n",
      "2011-11-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "Saving regular output at count = 75\n",
      "2011-12-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2012-01-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "Saving regular output at count = 113\n",
      "2012-02-01\n",
      "Saving regular output at count = 151\n",
      "2012-03-01\n",
      "Saving regular output at count = 188\n",
      "2012-04-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "Saving regular output at count = 226\n",
      "2012-05-01\n",
      "2012-06-01\n",
      "Saving regular output at count = 264\n",
      "2012-07-01\n",
      "Saving regular output at count = 302\n",
      "2012-08-01\n",
      "Saving regular output at count = 339\n",
      "2012-09-01\n",
      "Saving regular output at count = 377\n",
      "Saving validation output at specified date of: 2012-09-30 \n",
      "2012-10-01\n",
      "2012-11-01\n",
      "Saving regular output at count = 415\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2012-12-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "Saving regular output at count = 453\n",
      "2013-01-01\n",
      "Saving regular output at count = 490\n",
      "2013-02-01\n",
      "Saving regular output at count = 528\n",
      "2013-03-01\n",
      "2013-04-01\n",
      "Saving regular output at count = 566\n",
      "2013-05-01\n",
      "Saving regular output at count = 604\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2013-06-01\n",
      "Saving regular output at count = 641\n",
      "2013-07-01\n",
      "Saving regular output at count = 679\n",
      "2013-08-01\n",
      "Saving regular output at count = 717\n",
      "2013-09-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "Saving validation output at specified date of: 2013-09-30 \n",
      "2013-10-01\n",
      "Saving regular output at count = 755\n",
      "2013-11-01\n",
      "Saving regular output at count = 792\n",
      "2013-12-01\n",
      "Saving regular output at count = 830\n",
      "2014-01-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "Saving regular output at count = 868\n",
      "2014-02-01\n",
      "2014-03-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "Saving regular output at count = 906\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2014-04-01\n",
      "Saving regular output at count = 943\n",
      "2014-05-01\n",
      "Saving regular output at count = 981\n",
      "2014-06-01\n",
      "Saving regular output at count = 1019\n",
      "2014-07-01\n",
      "2014-08-01\n",
      "Saving regular output at count = 1057\n",
      "2014-09-01\n",
      "Saving regular output at count = 1095\n",
      "Saving validation output at specified date of: 2014-09-30 \n",
      "2014-10-01\n",
      "Saving regular output at count = 1132\n",
      "2014-11-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "Saving regular output at count = 1170\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2014-12-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "dt in model set to high flow dt of 10800.0\n",
      "SubstrateSplit\n",
      "SubstrateSplit\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2015-01-01\n",
      "Saving regular output at count = 1208\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2015-02-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "Saving regular output at count = 1246\n",
      "2015-03-01\n",
      "Saving regular output at count = 1283\n",
      "2015-04-01\n",
      "Saving regular output at count = 1321\n",
      "2015-05-01\n",
      "2015-06-01\n",
      "Saving regular output at count = 1359\n",
      "2015-07-01\n",
      "Saving regular output at count = 1397\n",
      "2015-08-01\n",
      "Saving regular output at count = 1434\n",
      "2015-09-01\n",
      "Saving regular output at count = 1472\n",
      "Saving validation output at specified date of: 2015-09-30 \n",
      "2015-10-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2015-11-01\n",
      "Saving regular output at count = 1510\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2015-12-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "Saving regular output at count = 1548\n",
      "2016-01-01\n",
      "Saving regular output at count = 1585\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2016-02-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "dt in model set to high flow dt of 10800.0\n",
      "Saving regular output at count = 1623\n",
      "2016-03-01\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2016-04-01\n",
      "Saving regular output at count = 1661\n",
      "2016-05-01\n",
      "Saving regular output at count = 1699\n",
      "2016-06-01\n",
      "Saving regular output at count = 1736\n",
      "2016-07-01\n",
      "Saving regular output at count = 1774\n",
      "2016-08-01\n",
      "Saving regular output at count = 1812\n",
      "2016-09-01\n",
      "Saving validation output at specified date of: 2016-09-30 \n",
      "2016-10-01\n",
      "Saving regular output at count = 1850\n",
      "dt in model set to high flow dt of 10800.0\n",
      "2016-11-01\n",
      "Saving regular output at count = 1887\n"
     ]
    }
   ],
   "source": [
    "    #  Checks to see if the specified output folder exists and creates it if it doesn't  \n",
    "    directory = str(os.path.join(os.pardir,inputs.Outputfolder))\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Creates a duration curve for the discharge record for a hydrograph run and\n",
    "    # creates a model object with the proper inputs.\n",
    "    run = \"\"\n",
    "    if inputs.Hydrograph == True:\n",
    "        newinputs = load_hydrographs(inputs)\n",
    "        run = clsModel(newinputs)\n",
    "    else:\n",
    "        run = clsModel(inputs)\n",
    "        \n",
    "    # Starts the model\n",
    "    run.RunModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4226653",
   "metadata": {},
   "source": [
    "### Start the animation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e9418c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Animator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9997ad1",
   "metadata": {},
   "source": [
    "This should start a widget that allows any of the attributes that were output in step XII.A to be animated on the screen. To use the animator tool, the user must navigate to the output folder that was specified at the beginning of step XII."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c653d",
   "metadata": {},
   "source": [
    "### Start the time series graphing tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "edd80554",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ATimeseriesPlotter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85860f",
   "metadata": {},
   "source": [
    "This should start a widget that allows up to three timeseries withing a given node to be plotted on a three-part figure. The locations and variables where output is available were specified in step XII.A. As with the animator tool, the user must navigate to the output folder that was specified at the beginning of step XII."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
